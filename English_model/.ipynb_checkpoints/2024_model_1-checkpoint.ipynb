{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6868,
     "status": "ok",
     "timestamp": 1703162067351,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "dzLKpmZICaWN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the seed value for experiment reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47225,
     "status": "ok",
     "timestamp": 1703162114565,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "4NtSh6iZNagy",
    "outputId": "517deb00-2d72-4240-ce3d-c8e00b7f8fb3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1703162114566,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "2-rayb7-3Y0I"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset/'\n",
    "data_dir = pathlib.Path(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgvFq3uYiS5G"
   },
   "source": [
    "The dataset's audio clips are stored in eight folders corresponding to each speech command: `no`, `yes`, `down`, `go`, `left`, `up`, `right`, and `stop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1952,
     "status": "ok",
     "timestamp": 1703162116515,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "70IBxSKxA1N9",
    "outputId": "902b877b-bf8a-4310-8507-8344428aa844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: ['right' 'LICENSE' 'backward' 'testing_list.txt' 'no'\n",
      " 'validation_list.txt' 'forward' 'left' 'stop']\n"
     ]
    }
   ],
   "source": [
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
    "print('Commands:', commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ7GJjDvHqtt"
   },
   "source": [
    "Divided into directories this way, you can easily load the data using `keras.utils.audio_dataset_from_directory`.\n",
    "\n",
    "The audio clips are 1 second or less at 16kHz. The `output_sequence_length=16000` pads the short ones to exactly 1 second (and would trim longer ones) so that they can be easily batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13076,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "mFM4c3aMC8Qv",
    "outputId": "2e187993-a0cf-40bc-9f86-9789dc3d0254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 6 classes.\n",
      "Using 4800 files for training.\n",
      "Using 1200 files for validation.\n",
      "\n",
      "label names: ['backward' 'forward' 'left' 'no' 'right' 'stop']\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    output_sequence_length=16000,\n",
    "    subset='both')\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print()\n",
    "print(\"label names:\", label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cestp83qFnU5"
   },
   "source": [
    "The dataset now contains batches of audio clips and integer labels. The audio clips have a shape of `(batch, samples, channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "3yU6SQGIFb3H",
    "outputId": "5aec1e38-a12d-405e-88a2-7ac98c1af3c8"
   },
   "outputs": [],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppG9Dgq2Ex8R"
   },
   "source": [
    "This dataset only contains single channel audio, so use the `tf.squeeze` function to drop the extra axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "Xl-tnniUIBlM"
   },
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "  audio = tf.squeeze(audio, axis=-1)\n",
    "  return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtsCSWZN5ILv"
   },
   "source": [
    "The utils.audio_dataset_from_directory function only returns up to two splits. It's a good idea to keep a test set separate from your validation set.\n",
    "Ideally you'd keep it in a separate directory, but in this case you can use Dataset.shard to split the validation set into two halves. Note that iterating over **any** shard will load **all** the data, and only keep its fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "u5UEGsqM5Gss"
   },
   "outputs": [],
   "source": [
    "test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "val_ds = val_ds.shard(num_shards=2, index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221726,
     "status": "ok",
     "timestamp": 1703162351307,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "xIeoJcwJH5h9",
    "outputId": "ca872edd-1bcf-4feb-8518-3ba24753764c"
   },
   "outputs": [],
   "source": [
    "for example_audio, example_labels in train_ds.take(1):\n",
    "  print(example_audio.shape)\n",
    "  print(example_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voxGEwvuh2L7"
   },
   "source": [
    "Let's plot a few audio waveforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1703162351308,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "dYtGq2zYNHuT",
    "outputId": "da394373-3e8a-4598-e1c6-ab07ad5d1719"
   },
   "outputs": [],
   "source": [
    "label_names[[1,1,3,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "executionInfo": {
     "elapsed": 4766,
     "status": "ok",
     "timestamp": 1703162356071,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "8yuX6Nqzf6wT",
    "outputId": "c06d4244-0e7e-4b7d-b8e9-34b763227291"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "rows = 3\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "for i in range(n):\n",
    "  plt.subplot(rows, cols, i+1)\n",
    "  audio_signal = example_audio[i]\n",
    "  plt.plot(audio_signal)\n",
    "  plt.title(label_names[example_labels[i]])\n",
    "  plt.yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "  plt.ylim([-1.1, 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1703162356072,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "_4CK75DHz_OR"
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rdPiPYJphs2"
   },
   "source": [
    "Next, start exploring the data. Print the shapes of one example's tensorized waveform and the corresponding spectrogram, and play the original audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1703162356072,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "4Mu6Y7Yz3C-V",
    "outputId": "e3bbd895-1a19-429f-c216-341cd2c57734"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  label = label_names[example_labels[i]]\n",
    "  waveform = example_audio[i]\n",
    "  spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "  print('Label:', label)\n",
    "  print('Waveform shape:', waveform.shape)\n",
    "  print('Spectrogram shape:', spectrogram.shape)\n",
    "  print('Audio playback')\n",
    "  display.display(display.Audio(waveform, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnSuqyxJ1isF"
   },
   "source": [
    "Now, define a function for displaying a spectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1703162356072,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "e62jzb36-Jog"
   },
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baa5c91e8603"
   },
   "source": [
    "Plot the example's waveform over time and the corresponding spectrogram (frequencies over time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "executionInfo": {
     "elapsed": 4652,
     "status": "ok",
     "timestamp": 1703162421737,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "d2_CikgY1tjv",
    "outputId": "6799eba9-0a67-46eb-ee1e-ebcfb3aa37bf"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 16000])\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.suptitle(label.title())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyYXjW07jCHA"
   },
   "source": [
    "Now, create spectrogram datasets from the audio datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1703162765777,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "mAD0LpkgqtQo"
   },
   "outputs": [],
   "source": [
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1703162769104,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "yEVb_oK0oBLQ"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "test_spectrogram_ds = make_spec_ds(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gQpAAgMnyDi"
   },
   "source": [
    "Examine the spectrograms for different examples of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaM2q5aGis-d"
   },
   "outputs": [],
   "source": [
    "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "executionInfo": {
     "elapsed": 5233,
     "status": "ok",
     "timestamp": 1703138427307,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "QUbHfTuon4iF",
    "outputId": "3ee28e33-11b1-4d3b-c0c0-6586e6b68414"
   },
   "outputs": [],
   "source": [
    "rows = 2\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 9))\n",
    "\n",
    "for i in range(n):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    plot_spectrogram(example_spectrograms[i].numpy(), ax)\n",
    "    ax.set_title(label_names[example_spect_labels[i].numpy()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5KdY8IF8rkt"
   },
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GS1uIh6F_TN9"
   },
   "source": [
    "Add `Dataset.cache` and `Dataset.prefetch` operations to reduce read latency while training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdZ6M-F5_QzY"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408700,
     "status": "ok",
     "timestamp": 1703138842661,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ALYz7PFCHblP",
    "outputId": "4cf09e2d-71f1-4971-c64a-451c6134d8b3"
   },
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(label_names)\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de52e5afa2f3"
   },
   "source": [
    "Configure the Keras model with the Adam optimizer and the cross-entropy loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFjj7-EmsTD-"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f42b9e3a4705"
   },
   "source": [
    "Train the model over 10 epochs for demonstration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379861,
     "status": "ok",
     "timestamp": 1703139278187,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ttioPJVMcGtq",
    "outputId": "32bf9ea7-432f-4942-d041-6d0b4c45543b"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjpCDeQ4mUfS"
   },
   "source": [
    "Let's plot the training and validation loss curves to check how your model has improved during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1703139349809,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "nzhipg3Gu2AY",
    "outputId": "24210bf5-8be1-40bb-9156-6894e9d4b957"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZTt3kO3mfm4"
   },
   "source": [
    "## Evaluate the model performance\n",
    "\n",
    "Run the model on the test set and check the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7154,
     "status": "ok",
     "timestamp": 1703139376174,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "FapuRT_SsWGQ",
    "outputId": "7e126f2f-b528-4a64-facb-a1d3a6d84e1e"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en9Znt1NOabH"
   },
   "source": [
    "### Display a confusion matrix\n",
    "\n",
    "Use a [confusion matrix](https://developers.google.com/machine-learning/glossary#confusion-matrix) to check how well the model did classifying each of the commands in the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1703139380080,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "5Y6vmWWQuuT1",
    "outputId": "ac6ec6b1-6281-4a79-b43e-fc05a58ae8d8"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_spectrogram_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6F0il82u7lW"
   },
   "outputs": [],
   "source": [
    "y_pred = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHSNoBYLvX81"
   },
   "outputs": [],
   "source": [
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1703139388572,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "LvoSAOiXU3lL",
    "outputId": "68f1975b-79c5-4fb3-c950-d259ae3a28ac"
   },
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQGi_mzPcLvl"
   },
   "source": [
    "## Run inference on an audio file\n",
    "\n",
    "Finally, verify the model's prediction output using an input audio file of someone saying \"no\". How well does your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 617,
     "status": "error",
     "timestamp": 1703139400782,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "zRxauKMdhofU",
    "outputId": "84e5e997-098c-43a4-e87e-cbb559741a53"
   },
   "outputs": [],
   "source": [
    "x = data_dir/'no/01bb6a2a_nohash_0.wav'\n",
    "x = tf.io.read_file(str(x))\n",
    "x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "x = tf.squeeze(x, axis=-1)\n",
    "waveform = x\n",
    "x = get_spectrogram(x)\n",
    "x = x[tf.newaxis,...]\n",
    "\n",
    "x_labels = ['backward','forward', 'left', 'no', 'right', 'stop']\n",
    "plt.bar(x_labels, tf.nn.softmax(prediction[0]))\n",
    "plt.title('No')\n",
    "plt.show()\n",
    "\n",
    "display.display(display.Audio(waveform, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgWICqdqQNaQ"
   },
   "source": [
    "As the output suggests, your model should have recognized the audio command as \"no\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1icqlM3ISW0"
   },
   "source": [
    "## Export the model with preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7HX-MjgIbji"
   },
   "source": [
    "The model's not very easy to use if you have to apply those preprocessing steps before passing data to the model for inference. So build an end-to-end version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lIeXdWjIbDE"
   },
   "outputs": [],
   "source": [
    "class ExportModel(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "    # Accept either a string-filename or a batch of waveforms.\n",
    "    # YOu could add additional signatures for a single wave, or a ragged-batch.\n",
    "    self.__call__.get_concrete_function(\n",
    "        x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "    self.__call__.get_concrete_function(\n",
    "       x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    # If they pass a string, load the file and decode it.\n",
    "    if x.dtype == tf.string:\n",
    "      x = tf.io.read_file(x)\n",
    "      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "      x = tf.squeeze(x, axis=-1)\n",
    "      x = x[tf.newaxis, :]\n",
    "\n",
    "    x = get_spectrogram(x)\n",
    "    result = self.model(x, training=False)\n",
    "\n",
    "    class_ids = tf.argmax(result, axis=-1)\n",
    "    class_names = tf.gather(label_names, class_ids)\n",
    "    return {'predictions':result,\n",
    "            'class_ids': class_ids,\n",
    "            'class_names': class_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtZBmUiB9HGY"
   },
   "source": [
    "Test run the \"export\" model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1702707817720,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "Z1_8TYaCIRue",
    "outputId": "312e1010-b8b8-46c2-c26b-2e2cc5ac01a7"
   },
   "outputs": [],
   "source": [
    "export = ExportModel(model)\n",
    "export(tf.constant(str(data_dir/'no/01bb6a2a_nohash_0.wav')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J6Iuz829Cxo"
   },
   "source": [
    "Save and reload the model, the reloaded model gives identical output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4757,
     "status": "ok",
     "timestamp": 1702707824661,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "wTAg4vsn3oEb",
    "outputId": "a81d9c57-d86e-4d20-c9f9-d5851aca4189"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(export, \"saved\")\n",
    "imported = tf.saved_model.load(\"saved\")\n",
    "imported(waveform[tf.newaxis, :])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
