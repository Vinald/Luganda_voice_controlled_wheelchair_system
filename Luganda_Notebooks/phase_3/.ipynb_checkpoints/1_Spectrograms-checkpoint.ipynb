{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357a0235-a6c0-4f01-8ceb-6cb31ecf9cf7",
   "metadata": {},
   "source": [
    "# Work FLow\n",
    "- `Packages and Libraries`\n",
    "-  `Load raw audio data` from files in .WAV format that can be processed\n",
    "-  `EDA`\n",
    "-  `Spectral Representations` Convert the audio signal into a frequency domain representation, such as a spectrogram or mel spectrogram.\n",
    "-  `Conversion to TensorFlow` Convert the preprocessed data into a format suitable for the deep learning framework.\n",
    "-  `Data Splitting` Split the dataset into training, validation, and testing sets.\n",
    "-  `Model Building` Build your machine learning model using the preprocessed data.\n",
    "-  `Converting to TFLite model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2a6da-a4eb-407b-86c9-69a8a7812540",
   "metadata": {},
   "source": [
    "# Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7333a2d7-3286-4385-bc48-2c3ff96ffca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 11:07:23.854992: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-07 11:07:23.939631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-07 11:07:23.939686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-07 11:07:23.941602: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-07 11:07:23.953594: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-07 11:07:23.954831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 11:07:26.207057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import wave\n",
    "import shutil\n",
    "\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "import soundfile as sf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3dc7d-5c61-4c4a-889b-92c80d9db1f7",
   "metadata": {},
   "source": [
    "# Loading Raw Audio Data File Paths\n",
    "\n",
    "The dataset's audio clips are of 6 classes and stored in six folders corresponding to each speech command: \n",
    "- `ddyo`\n",
    "- `kkono`\n",
    "- `mu maaso`\n",
    "- `emabega`\n",
    "- `yimirira`\n",
    "- `gaali`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beb872f-4907-4fd8-821a-e98cf8f4fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = 'Dataset/Train'\n",
    "TEST_DATASET_PATH = 'Dataset/Test'\n",
    "\n",
    "PROCESS_TRAIN_DATASET_PATH = 'Dataset/Process_train'\n",
    "PROCESS_TEST_DATASET_PATH = 'Dataset/Process_test'\n",
    "\n",
    "\n",
    "train_data_dir = pathlib.Path(TRAIN_DATASET_PATH)\n",
    "test_data_dir = pathlib.Path(TEST_DATASET_PATH)\n",
    "\n",
    "process_train_data_dir = pathlib.Path(PROCESS_TRAIN_DATASET_PATH)\n",
    "process_test_data_dir = pathlib.Path(PROCESS_TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ba2f7-ba6d-486c-a12c-b5948310c0b9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3c036-eb33-4b80-a896-e4be35beed64",
   "metadata": {},
   "source": [
    "## 1. Duration(2s), and channel (mono) check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41613941-e000-44b7-a85d-f5a0adee8597",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/Train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmove_audio_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_train_data_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m move_audio_files(test_data_dir, process_test_data_dir)\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mmove_audio_files\u001b[0;34m(data_dir, process_folder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(process_folder):\n\u001b[1;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(process_folder)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m     subfolder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, subfolder)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(subfolder_path):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/Train'"
     ]
    }
   ],
   "source": [
    "def move_audio_files(data_dir, process_folder):\n",
    "    if not os.path.exists(process_folder):\n",
    "        os.makedirs(process_folder)\n",
    "\n",
    "    for subfolder in os.listdir(data_dir):\n",
    "        subfolder_path = os.path.join(data_dir, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for audio_file in os.listdir(subfolder_path):\n",
    "                audio_path = os.path.join(subfolder_path, audio_file)\n",
    "                try:\n",
    "                    # Get audio length and number of channels\n",
    "                    with wave.open(audio_path, 'r') as wav_file:\n",
    "                        audio_length = wav_file.getnframes() / wav_file.getframerate()\n",
    "                        num_channels = wav_file.getnchannels()\n",
    "\n",
    "                    if audio_length > 2.0 or num_channels != 1:\n",
    "                        # Move the audio file to the process folder\n",
    "                        shutil.move(audio_path, os.path.join(process_folder, audio_file))\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing {audio_path}: {e}')\n",
    "\n",
    "\n",
    "move_audio_files(train_data_dir, process_train_data_dir)\n",
    "move_audio_files(test_data_dir, process_test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bce7b-8cdf-4913-a5c9-1a5548da0791",
   "metadata": {},
   "source": [
    "## 2. Count audio files function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d354312-1db9-4b57-aa43-abe05c254137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_audio_files_in_subfolders(data_dir):\n",
    "    counts = {}\n",
    "    for subfolder in os.listdir(data_dir):\n",
    "        subfolder_path = os.path.join(data_dir, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            audio_files_count = len([f for f in os.listdir(subfolder_path) if f.endswith('.wav')])\n",
    "            counts[subfolder] = audio_files_count\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b447d4-672d-45af-8e67-675234f1c6f6",
   "metadata": {},
   "source": [
    "## 3. Function to determine the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5f2e5-1a4e-471a-ab5d-f64c989b7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size\n",
    "\n",
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
    "    elif unit == \"MB\":\n",
    "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
    "    else:\n",
    "        return print('File size: ' + str(size) + ' bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57942a50-014d-4a25-b1fa-120ac44c0d66",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591c7e6-e557-4e1a-8ec5-08c55b59017c",
   "metadata": {},
   "source": [
    "## Labels (Train and Test Directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db1d8a-0530-4f2f-8488-73eabacd15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = np.array(tf.io.gfile.listdir(str(train_data_dir)))\n",
    "print(f'Train commands labels: {commands}')\n",
    "\n",
    "commands = np.array(tf.io.gfile.listdir(str(test_data_dir)))\n",
    "print(f'Test commands labels:  {commands}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f1644-58cb-4758-b279-a5af57279bde",
   "metadata": {},
   "source": [
    "## Number of audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3345fc-7bd1-40fa-810f-94a24499725f",
   "metadata": {},
   "source": [
    "### 1. Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb130c77-d774-426f-ac55-407242a79db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = count_audio_files_in_subfolders(train_data_dir)\n",
    "print(f'Train \\n{counts}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb065641-9f95-47af-9197-9be3a03d9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(list(counts.keys()), list(counts.values()), color='purple')\n",
    "plt.xlabel('Number of Audio Files')\n",
    "plt.ylabel('Command labels')\n",
    "plt.title('Number of Audio Files For Training for Each Command')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94519b4f-df5e-4919-a424-5b0d17e3e8e0",
   "metadata": {},
   "source": [
    "### 2. Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f9838-cf4d-4f2a-ad2d-ddffd0dcd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = count_audio_files_in_subfolders(test_data_dir)\n",
    "print(f'Test \\n{counts}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0adca-1d89-4d09-bf6b-17b272d108da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(list(counts.keys()), list(counts.values()), color='purple')\n",
    "plt.xlabel('Number of Audio Files')\n",
    "plt.ylabel('Command labels')\n",
    "plt.title('Number of Audio Files For Training for Each Command')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab20a2-4884-4749-b5e3-df3b80de6c90",
   "metadata": {},
   "source": [
    "## Audio Properties and Parameters\n",
    "- using one audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb792d9f-e196-4d2f-b49a-5637369e68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_audio_path = os.path.join(TRAIN_DATASET_PATH, 'ddyo', 'ddyo #107.wav')\n",
    "audio_signal, sample_rate = librosa.load(example_audio_path, sr=SAMPLE_RATE)\n",
    "audio = wave.open(example_audio_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b13791-7dfe-4c02-9cf1-ea199c24192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = audio.getnchannels()\n",
    "sample_width = audio.getsampwidth()\n",
    "frame_rate = audio.getframerate()\n",
    "num_frames = audio.getnframes()\n",
    "duration = num_frames / float(frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95ec3f-7947-4d4c-83c2-2d9e1d6bf551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Audio Properties for a ddyo audio file')\n",
    "print(f\"Number of channels:   {num_channels}\")\n",
    "print(f\"Sample width (bytes): {sample_width}\")\n",
    "print(f\"Frame rate (Hz):      {frame_rate}\")\n",
    "print(f\"Number of frames:     {num_frames}\")\n",
    "print(f\"Duration (s):         {duration}\")\n",
    "# print(\"Parameters:            \", audio.getparams())\n",
    "audio.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b9871-42ce-404e-8719-a108f4ea26f0",
   "metadata": {},
   "source": [
    "## Visualize the audio waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19752c3e-4ae1-4bee-a448-249c2841b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddyo_file_path = os.path.join(TRAIN_DATASET_PATH, 'ddyo', 'ddyo #107.wav')\n",
    "kkono_file_path = os.path.join(TRAIN_DATASET_PATH, 'kkono', 'kkono #67.wav')\n",
    "emabega_file_path = os.path.join(TRAIN_DATASET_PATH, 'emabega', 'emabega #225.wav')\n",
    "mumasso_file_path = os.path.join(TRAIN_DATASET_PATH, 'mu masso', 'mu masso #140.wav')\n",
    "yimirira_file_path = os.path.join(TRAIN_DATASET_PATH, 'yimirira', 'yimirira-3 #58-05.wav')\n",
    "gaali_file_path = os.path.join(TRAIN_DATASET_PATH, 'gaali', 'gaali #371.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9780df-ceb4-4808-892d-af9597244cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = [\n",
    "    ddyo_file_path,\n",
    "    kkono_file_path,\n",
    "    emabega_file_path,\n",
    "    mumasso_file_path,\n",
    "    yimirira_file_path,\n",
    "    gaali_file_path\n",
    "]\n",
    "\n",
    "label_names_slice = ['Ddyo', 'Kkono', 'Emabega', 'Mu masso', 'Yimirira', 'Gaali']\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "rows = 2\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "for i in range(n):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    audio_path = audio_files[i]  # Get the path to the audio file\n",
    "    audio_signal, _ = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
    "    time = librosa.times_like(audio_signal, sr=SAMPLE_RATE)\n",
    "    plt.plot(time, audio_signal)\n",
    "    plt.title(label_names_slice[i])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.ylim([-1.1, 1.1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde0a0f-d84f-4d13-beb8-d1afd4615343",
   "metadata": {},
   "source": [
    "## Play audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646afe09-b8ea-491b-9731-063986a5f8cc",
   "metadata": {},
   "source": [
    "Ddyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cf40d-0dd6-41dd-a985-2b588b1f0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(ddyo_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd3a800-955d-4c90-a63e-13264eac7063",
   "metadata": {},
   "source": [
    "Kkono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ed761-d492-4962-ae1c-b0b0632e4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(kkono_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af6c1a-9c51-4af5-8241-840386fb2268",
   "metadata": {},
   "source": [
    "Emabega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85264e96-adf4-43e6-b821-74cfa5124b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(emabega_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3389141-dc10-487c-9933-f98afa759cbe",
   "metadata": {},
   "source": [
    "Mu masso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4c359-2996-465f-8a34-e81f32429b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(mumasso_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc628ad-17ab-43e7-8f01-4d1d25571408",
   "metadata": {},
   "source": [
    "Yimirira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adbbc9e-408c-4380-bad7-160909f94b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(yimirira_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc2204-f4b8-4248-a45a-2bd0d542503c",
   "metadata": {},
   "source": [
    "Gaali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fa331-b7ec-4b3d-bcb0-3cfca9c51ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(gaali_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715af78-f292-4688-a03d-15ee0faea635",
   "metadata": {},
   "source": [
    "# Dataset Preparaption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62fe9d-a160-47bc-ac41-d93c14dfbabd",
   "metadata": {},
   "source": [
    "## 1. Train and validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ca8ea-6ba0-4cfc-965f-3787b187f07e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13076,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "mFM4c3aMC8Qv",
    "outputId": "2e187993-a0cf-40bc-9f86-9789dc3d0254"
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=train_data_dir,\n",
    "    batch_size=64,\n",
    "    validation_split=0.3,\n",
    "    seed=0,\n",
    "    output_sequence_length=SAMPLE_RATE,\n",
    "    subset='both')\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50728717-5244-45c3-af05-d1b2520f40be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "3yU6SQGIFb3H",
    "outputId": "5aec1e38-a12d-405e-88a2-7ac98c1af3c8"
   },
   "outputs": [],
   "source": [
    "element_spec = train_ds.element_spec\n",
    "print(element_spec)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7dd5b-b350-4838-b225-367958fb8953",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1703162129584,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "Xl-tnniUIBlM"
   },
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "  audio = tf.squeeze(audio, axis=-1)\n",
    "  return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304479f1-440c-402a-90f4-37c0c90f5021",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221726,
     "status": "ok",
     "timestamp": 1703162351307,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "xIeoJcwJH5h9",
    "outputId": "ca872edd-1bcf-4feb-8518-3ba24753764c"
   },
   "outputs": [],
   "source": [
    "# Inspecting the shape of the audio and label\n",
    "\n",
    "for example_audio, example_labels in train_ds.take(1):\n",
    "  print(example_audio.shape)\n",
    "  print(example_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc118573-9909-4ac6-91a4-12506f945eee",
   "metadata": {},
   "source": [
    "## 2. Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ce0b0-6587-4cfb-9a51-0a7b6632d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=test_data_dir,\n",
    "    batch_size=64,\n",
    "    validation_split=None,  # No need to split the test dataset\n",
    "    seed=0,\n",
    "    output_sequence_length=SAMPLE_RATE,\n",
    "    shuffle=False  # Disable shuffling for the test dataset\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(squeeze, tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ab331-4681-4193-8a47-0b8078f6f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_audio, example_labels in test_ds.take(1):\n",
    "  print(example_audio.shape)\n",
    "  print(example_labels.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde53bef-0304-4d2d-962f-61670c3107ac",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d386de3-86f8-4a43-9f73-30df2e4a93dc",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1703162356072,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "_4CK75DHz_OR"
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=255, frame_step=128)\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8313a8-83ff-4ee0-afb9-b71d89b7300f",
   "metadata": {
    "id": "5rdPiPYJphs2"
   },
   "source": [
    "## Tensorized waveform\n",
    "The shapes of a tensorized waveform and the corresponding spectrogram, and play the original audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6936d-e9d9-4b31-bad6-6b7704c4fa48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1703162356072,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "4Mu6Y7Yz3C-V",
    "outputId": "e3bbd895-1a19-429f-c216-341cd2c57734"
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "  label = label_names[example_labels[i]]\n",
    "  waveform = example_audio[i]\n",
    "  spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "  print('Label:', label)\n",
    "  print('Waveform shape:', waveform.shape)\n",
    "  print('Spectrogram shape:', spectrogram.shape)\n",
    "  print('Audio playback')\n",
    "  display.display(display.Audio(waveform, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e8e9a-8b3a-4195-a534-3a8b81533e35",
   "metadata": {
    "id": "xnSuqyxJ1isF"
   },
   "source": [
    "### Visualization of spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f35de-fb02-43c4-8618-79680428db73",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1703162356072,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "e62jzb36-Jog"
   },
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "      \n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090cf84-93fc-498c-a11c-1d6b32117f09",
   "metadata": {
    "id": "baa5c91e8603"
   },
   "source": [
    "### Plot of waveform and spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5462a7-a338-4be0-8146-32727c7ab8a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "executionInfo": {
     "elapsed": 4652,
     "status": "ok",
     "timestamp": 1703162421737,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "d2_CikgY1tjv",
    "outputId": "6799eba9-0a67-46eb-ee1e-ebcfb3aa37bf"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 16000])\n",
    "\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.suptitle(label.title())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e1f30-76cc-4625-990a-98a833fa79c4",
   "metadata": {
    "id": "GyYXjW07jCHA"
   },
   "source": [
    "## Create spectrogram datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246f298-efed-44ed-af59-fac9d0e4e48e",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1703162765777,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "mAD0LpkgqtQo"
   },
   "outputs": [],
   "source": [
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4f368-82fd-44d0-8a67-1c2dad901be8",
   "metadata": {
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1703162769104,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "yEVb_oK0oBLQ"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "test_spectrogram_ds = make_spec_ds(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb095cf4-b10a-492d-ae7c-291fd1e537ad",
   "metadata": {
    "id": "fdZ6M-F5_QzY"
   },
   "outputs": [],
   "source": [
    "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c8626-09f0-440f-a375-99bf12ddb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spectrogram_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3a85e-9ede-4126-8e5a-12f645aa7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_spectrogram_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46604e82-2caa-468c-bda2-12c13d56b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spectrogram_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb00f3-9b92-4cd7-92e3-82b0615966eb",
   "metadata": {
    "id": "6gQpAAgMnyDi"
   },
   "source": [
    "## Visualization of the spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672613c-9bce-4cd2-814e-3077d16704b5",
   "metadata": {
    "id": "EaM2q5aGis-d"
   },
   "outputs": [],
   "source": [
    "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00faf20-dfea-4090-83e9-d32c39be0aed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "executionInfo": {
     "elapsed": 5233,
     "status": "ok",
     "timestamp": 1703138427307,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "QUbHfTuon4iF",
    "outputId": "3ee28e33-11b1-4d3b-c0c0-6586e6b68414",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = 2\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 9))\n",
    "\n",
    "for i in range(n):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    plot_spectrogram(example_spectrograms[i].numpy(), ax)\n",
    "    ax.set_title(label_names[example_spect_labels[i].numpy()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10779cc1-65ed-48ba-bd07-ead7c2e3a2ac",
   "metadata": {},
   "source": [
    "# Packages and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf56b18-0147-487c-8e7e-5a193a7daad0",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238df87-4250-45f2-a6e5-5f13c3414812",
   "metadata": {
    "id": "z5KdY8IF8rkt"
   },
   "source": [
    "## Model 1\n",
    "\n",
    "1. **Input Layer:** Defines the input shape for the model based on the shape of the spectrogram images.\n",
    "2. **Resizing Layer:** Resizes the input spectrogram images to a fixed size of 32x32 pixels.\n",
    "3. **Normalization Layer:** Normalizes the input data using statistics computed from the training dataset.\n",
    "4. **Convolutional Layers:** Two Conv2D layers with ReLU activation functions, followed by max pooling.\n",
    "5. **Dropout Layer:** Applies dropout regularization to prevent overfitting.\n",
    "6. **Flatten Layer:** Flattens the output of the previous layer into a 1D vector.\n",
    "7. **Dense Layers:** Two Dense layers with ReLU activation functions, followed by the output layer with logits for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007c25f-e8fa-4a5e-9109-be576662e369",
   "metadata": {},
   "source": [
    "### Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa2d13-b3fd-4cf9-93e3-a32f594b8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db4367-53ae-4cf9-b079-51655909be68",
   "metadata": {},
   "source": [
    "### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602bbee-2e90-425c-9ee1-22ee84f4a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_names)\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9dc29-4410-4e41-bcf2-4436aa9c2b67",
   "metadata": {},
   "source": [
    "### Model Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a84caa-6c3d-4e80-8a5c-930ff1916937",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408700,
     "status": "ok",
     "timestamp": 1703138842661,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ALYz7PFCHblP",
    "outputId": "4cf09e2d-71f1-4971-c64a-451c6134d8b3"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Resizing(32, 32),\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3378e2-070e-409c-ad1c-189ba812fc5e",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75336bf6-9ecc-4127-bdaa-02220f0bd71b",
   "metadata": {
    "id": "wFjj7-EmsTD-"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd1e78-3a1f-4d23-82c8-fc0d5b009c27",
   "metadata": {
    "id": "f42b9e3a4705"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf44f9a-b817-419a-832f-ca547af5a6b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379861,
     "status": "ok",
     "timestamp": 1703139278187,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ttioPJVMcGtq",
    "outputId": "32bf9ea7-432f-4942-d041-6d0b4c45543b"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69d4c8-7019-45f9-9961-ac0e457049fe",
   "metadata": {
    "id": "gjpCDeQ4mUfS"
   },
   "source": [
    "### Plot Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c876d81f-30b8-4cb4-afcd-eb1cfd3d4e4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1703139349809,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "nzhipg3Gu2AY",
    "outputId": "24210bf5-8be1-40bb-9156-6894e9d4b957"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746daa3a-e18a-4700-9e43-fd76a1011e90",
   "metadata": {
    "id": "5ZTt3kO3mfm4"
   },
   "source": [
    "### Evaluate the model performance\n",
    "\n",
    "Run the model on the test set and check the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867dea7-7633-4c19-ae10-8c9d19706edd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7154,
     "status": "ok",
     "timestamp": 1703139376174,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "FapuRT_SsWGQ",
    "outputId": "7e126f2f-b528-4a64-facb-a1d3a6d84e1e"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baae0c-28b0-447e-b9dc-5b940c9af0ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1703139380080,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "5Y6vmWWQuuT1",
    "outputId": "ac6ec6b1-6281-4a79-b43e-fc05a58ae8d8"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_spectrogram_ds)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c9174-68df-4ae8-b553-0154a085cd78",
   "metadata": {
    "id": "d6F0il82u7lW"
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")\n",
    "print(f\"F1-score:  {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67f6a0-900c-423d-89c0-32727b79f898",
   "metadata": {
    "id": "en9Znt1NOabH"
   },
   "source": [
    "### Display a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c71d1-c788-4bbe-8ea2-03bf162d2bd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1703139388572,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "LvoSAOiXU3lL",
    "outputId": "68f1975b-79c5-4fb3-c950-d259ae3a28ac"
   },
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c463a5-df1b-4a40-a061-f0d6f24b679f",
   "metadata": {},
   "source": [
    "## Save the TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aed926-4b81-4b16-83d4-b6f32bd4326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"model_1.keras\"\n",
    "model.save(KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596a0ba-7198-4998-afa8-6d21d3fd8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f9543-052a-4544-ae3d-4ff5fb2f7b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f79c72c-eac2-4433-91f5-88cde7a3d64b",
   "metadata": {
    "id": "mQGi_mzPcLvl"
   },
   "source": [
    "## Model 2\n",
    "\n",
    "\n",
    "1. **Input Layer**: Defines the input shape for the model based on the shape of the spectrogram images.\n",
    "2. **Resizing Layer**: Resizes the input spectrogram images to a fixed size of 32x32 pixels.\n",
    "3. **Normalization Layer**: Normalizes the input data using statistics computed from the training dataset.\n",
    "4. **Convolutional Layers**:\n",
    "   - 4.1. First Conv2D Layer: Applies 32 filters with a 3x3 kernel size and ReLU activation function.\n",
    "   - 4.2. Batch Normalization Layer: Normalizes the activations of the previous convolutional layer.\n",
    "   - 4.3. MaxPooling2D Layer: Performs max pooling to downsample the feature maps.\n",
    "5. **Convolutional Layers**:\n",
    "   - 5.1. Second Conv2D Layer: Applies 64 filters with a 3x3 kernel size and ReLU activation function.\n",
    "   - 5.2. Batch Normalization Layer: Normalizes the activations of the previous convolutional layer.\n",
    "   - 5.3. MaxPooling2D Layer: Performs max pooling to downsample the feature maps.\n",
    "6. **Dropout Layer**: Applies dropout regularization with a dropout rate of 0.25 to prevent overfitting.\n",
    "7. **Flatten Layer**: Flattens the output of the previous layer into a 1D vector.\n",
    "8. **Dense Layers**:\n",
    "   - 8.1. First Dense Layer: Applies 128 neurons with ReLU activation function.\n",
    "   - 8.2. Dropout Layer: Applies dropout regularization with a dropout rate of 0.5.\n",
    "   - 8.3. Second Dense Layer: Outputs logits for each class, with the number of units equal to the number of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cf3ac-3f01-49ad-9c02-38b547ee7316",
   "metadata": {},
   "source": [
    "### Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d5173-643d-4aa2-8144-d512bc9fd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d26704-417d-4cbf-837b-9c6677805881",
   "metadata": {},
   "source": [
    "### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688fe03-de73-4dca-b224-ea0e88e12243",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_names)\n",
    "norm_layer = layers.Normalization()\n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef78467-6bab-4431-a12b-ab6ea40621b4",
   "metadata": {},
   "source": [
    "### Model Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd8f5a-1d38-41b2-9062-71cdc7d61f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Resizing(32, 32),\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3933c92-6034-43b9-81e4-700e153e6f81",
   "metadata": {},
   "source": [
    "### Compile the  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2a078-9004-4daf-98ea-c2d52d826da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "timizer=tf.keras.optimizers.Adam(),\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97378ef6-cb29-44eb-9211-1e488f1f26b6",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84de04-334e-4010-b4f4-7c9a85b7494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model_2.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f16581-a287-4584-b675-8b2b11f74e4d",
   "metadata": {
    "id": "gjpCDeQ4mUfS"
   },
   "source": [
    "### Plot Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918321d-6306-4480-862d-f6516b88e608",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1703139349809,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "nzhipg3Gu2AY",
    "outputId": "24210bf5-8be1-40bb-9156-6894e9d4b957"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec9e22-68cb-4efd-bc29-1048f9e0eee8",
   "metadata": {
    "id": "5ZTt3kO3mfm4"
   },
   "source": [
    "### Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab70fa0-87d3-453c-8166-91037d9e331e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7154,
     "status": "ok",
     "timestamp": 1703139376174,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "FapuRT_SsWGQ",
    "outputId": "7e126f2f-b528-4a64-facb-a1d3a6d84e1e"
   },
   "outputs": [],
   "source": [
    "model_2.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3412d5c-2503-4f91-b64a-9bac01d118a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1703139380080,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "5Y6vmWWQuuT1",
    "outputId": "ac6ec6b1-6281-4a79-b43e-fc05a58ae8d8"
   },
   "outputs": [],
   "source": [
    "y_pred = model_2.predict(test_spectrogram_ds)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc5501-f12c-445f-a9a3-d965869a7513",
   "metadata": {
    "id": "d6F0il82u7lW"
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")\n",
    "print(f\"F1-score:  {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9fb06-7c8b-4b50-ae63-5724346c7cb5",
   "metadata": {
    "id": "vHSNoBYLvX81"
   },
   "source": [
    "### Display the confusion matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c19297-2bc3-43b3-98d0-2c1d01f7d498",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1703139388572,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "LvoSAOiXU3lL",
    "outputId": "68f1975b-79c5-4fb3-c950-d259ae3a28ac"
   },
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43823306-d3a3-46df-bd42-812fb7ef8410",
   "metadata": {},
   "source": [
    "## Save the TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2d93d-4eec-4779-9919-fe89b1d128f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"model_2.keras\"\n",
    "model_2.save(KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8e158-ba59-43f5-a4e5-84d014d4ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421511ad-f07e-40ba-89a6-8bcda246dc1c",
   "metadata": {
    "id": "z5KdY8IF8rkt"
   },
   "source": [
    "## Model 3\n",
    "\n",
    "1. **Input Layer**: Defines the input shape for the model based on the shape of the spectrogram images.\n",
    "2. **Convolutional Layers**:\n",
    "   - 2.1. First Conv2D Layer: Applies 32 filters with a 3x3 kernel size, ReLU activation function, and dilation rate of (2, 2).\n",
    "   - 2.2. MaxPooling2D Layer: Performs max pooling to downsample the feature maps.\n",
    "3. **Convolutional Layers**:\n",
    "   - 3.1. Second Conv2D Layer: Applies 64 filters with a 3x3 kernel size, ReLU activation function, and dilation rate of (2, 2).\n",
    "   - 3.2. MaxPooling2D Layer: Performs max pooling to downsample the feature maps.\n",
    "4. **Convolutional Layers**:\n",
    "   - 4.1. Third Conv2D Layer: Applies 128 filters with a 3x3 kernel size, ReLU activation function, and dilation rate of (2, 2).\n",
    "   - 4.2. GlobalAveragePooling2D Layer: Performs global average pooling to reduce spatial dimensions.\n",
    "5. **Dense Layers**:\n",
    "   - 5.1. Dense Layer: Applies 128 neurons with ReLU activation function.\n",
    "   - 5.2. Dropout Layer: Applies dropout regularization with a dropout rate of 0.5.\n",
    "   - 5.3. Dense Layer: Outputs logits for each class, with the number of units equal to the number of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bdbd4-a967-4a5b-bee4-67bd81d77315",
   "metadata": {},
   "source": [
    "### Input shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb64bab-80b5-4626-b8d6-c88472a9084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5b928-d2c6-42ce-b10c-67ce4beb2b86",
   "metadata": {},
   "source": [
    "### Model Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa203f1b-1ff9-42b9-bbb0-612e298a7aa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408700,
     "status": "ok",
     "timestamp": 1703138842661,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ALYz7PFCHblP",
    "outputId": "4cf09e2d-71f1-4971-c64a-451c6134d8b3"
   },
   "outputs": [],
   "source": [
    "model_3 = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, 3, activation='relu', dilation_rate=(2, 2)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu', dilation_rate=(2, 2)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu', dilation_rate=(2, 2)),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model_3.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70606c22-bf4e-4d8c-9082-60865a8b1850",
   "metadata": {
    "id": "de52e5afa2f3"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d34b4-d88b-457b-8b07-b2589a2751ce",
   "metadata": {
    "id": "wFjj7-EmsTD-"
   },
   "outputs": [],
   "source": [
    "model_3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fdfb6-a67c-4c9c-9f40-e509c8e32efc",
   "metadata": {
    "id": "f42b9e3a4705"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96543c8f-66b1-4196-8f12-cb814559b66d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379861,
     "status": "ok",
     "timestamp": 1703139278187,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ttioPJVMcGtq",
    "outputId": "32bf9ea7-432f-4942-d041-6d0b4c45543b"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model_3.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1224b-ecbf-4c47-a970-fcb17edb0ede",
   "metadata": {
    "id": "gjpCDeQ4mUfS"
   },
   "source": [
    "### Plot Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39a107-c706-4c3b-9ad8-1a988efd245f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1703139349809,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "nzhipg3Gu2AY",
    "outputId": "24210bf5-8be1-40bb-9156-6894e9d4b957"
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c45fb8-040d-4255-ac4b-1aba2cd11dfd",
   "metadata": {
    "id": "5ZTt3kO3mfm4"
   },
   "source": [
    "### Evaluate the model performance\n",
    "\n",
    "Run the model on the test set and check the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d5d75-f072-4b56-9b6e-f6935acaa191",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7154,
     "status": "ok",
     "timestamp": 1703139376174,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "FapuRT_SsWGQ",
    "outputId": "7e126f2f-b528-4a64-facb-a1d3a6d84e1e"
   },
   "outputs": [],
   "source": [
    "model_3.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc868cc8-d23c-4135-9bcd-a182e80ba58b",
   "metadata": {
    "id": "en9Znt1NOabH"
   },
   "source": [
    "### Display a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ed9a7-0554-443c-92e3-4bea63718394",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1703139380080,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "5Y6vmWWQuuT1",
    "outputId": "ac6ec6b1-6281-4a79-b43e-fc05a58ae8d8"
   },
   "outputs": [],
   "source": [
    "y_pred = model_3.predict(test_spectrogram_ds)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07724a12-d181-4a71-9f23-0ea904825d2c",
   "metadata": {
    "id": "d6F0il82u7lW"
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")\n",
    "print(f\"F1-score:  {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074df7af-3e87-4d81-9cf1-50127b5e8d7d",
   "metadata": {
    "id": "vHSNoBYLvX81"
   },
   "source": [
    "## Display the confusion matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579284e5-ea17-4a55-b600-5bf62b0d4b62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1703139388572,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "LvoSAOiXU3lL",
    "outputId": "68f1975b-79c5-4fb3-c950-d259ae3a28ac"
   },
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cd4b1-88aa-49ec-9935-c239636b2fc1",
   "metadata": {},
   "source": [
    "## Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b31067-a6e4-4bbb-826a-2eb1343364e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"model_3.keras\"\n",
    "model_3.save(KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9a78a-a097-424b-a655-24d86918874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39705c0f-4fb1-46eb-8c58-c520a5330a20",
   "metadata": {
    "id": "z5KdY8IF8rkt"
   },
   "source": [
    "## Model 4\n",
    "\n",
    "1. Input layer: Accepts input data of shape `input_shape`.\n",
    "2. Conv2D layer with 32 filters, kernel size 3x3, and ReLU activation. Dilated convolution with dilation rate (2, 2).\n",
    "3. MaxPooling2D layer.\n",
    "4. Conv2D layer with 64 filters, kernel size 3x3, and ReLU activation. Dilated convolution with dilation rate (2, 2).\n",
    "5. GlobalAveragePooling2D layer: Reduces spatial dimensions to 1x1.\n",
    "6. Dense layer with 64 neurons and ReLU activation.\n",
    "7. Dropout layer with dropout rate of 0.5.\n",
    "8. Dense output layer with `num_labels` neurons (output classes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb9385-9d8f-4a2f-afb7-2e9cfe91e59f",
   "metadata": {},
   "source": [
    "### Input shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06553c99-2d83-4c37-a0ae-591b9896ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693324ab-676e-4332-bb1d-d7eb689d0578",
   "metadata": {},
   "source": [
    "### Model Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81213349-d4d0-46af-a50f-e3fe9d702bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, 3, activation='relu', dilation_rate=(2, 2)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu', dilation_rate=(2, 2)),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718fcf2-d76b-48f0-b5e0-e794595a801c",
   "metadata": {
    "id": "de52e5afa2f3"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d130acd-baa8-4992-8301-a673513c4de7",
   "metadata": {
    "id": "wFjj7-EmsTD-"
   },
   "outputs": [],
   "source": [
    "model_4.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a2bbb-9019-4b23-9c32-64d6b4d00e98",
   "metadata": {
    "id": "f42b9e3a4705"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947ce38-36c7-4e0d-94d3-e494cce51c77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379861,
     "status": "ok",
     "timestamp": 1703139278187,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "ttioPJVMcGtq",
    "outputId": "32bf9ea7-432f-4942-d041-6d0b4c45543b"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model_4.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79884280-79fc-4c2a-aee3-0f88c7586c57",
   "metadata": {},
   "source": [
    "### Plot Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17341cd0-aeb8-4be5-838d-812cbd6e8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ceadfe-8bdf-46ca-8735-362784e965df",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecab7a3-b92c-4234-9183-00e5cc75a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.evaluate(test_spectrogram_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3da57-9069-4b7f-aa0c-1ff44498fdcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1703139380080,
     "user": {
      "displayName": "adi sam",
      "userId": "04727694002057940011"
     },
     "user_tz": -180
    },
    "id": "5Y6vmWWQuuT1",
    "outputId": "ac6ec6b1-6281-4a79-b43e-fc05a58ae8d8"
   },
   "outputs": [],
   "source": [
    "y_pred = model_4.predict(test_spectrogram_ds)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523a176-57c4-400a-968a-d0834af4fc68",
   "metadata": {
    "id": "d6F0il82u7lW"
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall:    {recall}\")\n",
    "print(f\"F1-score:  {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32b71-5152-4bde-9bf8-a51578cc6074",
   "metadata": {},
   "source": [
    "### Display a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed0826-f03f-4e28-a84c-3343dfa111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_4.predict(test_spectrogram_ds)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.concat(list(test_spectrogram_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9dbc2-f2ca-40a8-b5f4-2f2d42c97124",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=label_names,\n",
    "            yticklabels=label_names,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c297d-81db-4045-82e9-a80d97a3bdee",
   "metadata": {},
   "source": [
    "## Save the TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47421e-0b69-4219-8f3b-0abad8b82633",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"model_4.keras\"\n",
    "model_4.save(KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464d60b-0a9e-40c7-bb96-c9e2f5f3024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
