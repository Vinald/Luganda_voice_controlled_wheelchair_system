{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee297e3-d574-42fa-93ba-91a213198e50",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893e0989-c2f9-4b0c-8cf4-832cff38ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 13:29:59.762399: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 13:29:59.800115: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 13:29:59.800145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 13:29:59.801127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-08 13:29:59.806372: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 13:29:59.806877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 13:30:00.746575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "# from google.colab import drive\n",
    "import wave\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import librosa\n",
    "import IPython.display as display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a8081-7eb7-480d-9392-99c5f46f175d",
   "metadata": {},
   "source": [
    "### Load on audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704b6bf2-8ab7-47b7-88a0-7edcaa5b9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = 'Dataset/Train'\n",
    "TEST_DATASET_PATH = 'Dataset/Test'\n",
    "\n",
    "train_data_dir = pathlib.Path(TRAIN_DATASET_PATH)\n",
    "test_data_dir = pathlib.Path(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e4b4a4-479f-428f-bea9-743c59d50141",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "DURATION = 2  # in seconds\n",
    "SAMPLES_PER_AUDIO = SAMPLE_RATE * DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b6e0d7-3f57-4b3e-9bf8-432a4c17f35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vx/Desktop/allenv/lib/python3.10/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  >>> import audioread.ffdec  # Use ffmpeg decoder\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/Train/emabega/audio #4251.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/librosa/core/audio.py:149\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     56\u001b[0m     path: Union[\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[Any], sf\u001b[38;5;241m.\u001b[39mSoundFile, audioread\u001b[38;5;241m.\u001b[39mAudioFile, BinaryIO\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     res_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoxr_hq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load an audio file as a floating point time series.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Audio will be automatically resampled to the given rate\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    (default ``sr=22050``).\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    To preserve the native sampling rate of the file, use ``sr=None``.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    path : string, int, pathlib.Path, soundfile.SoundFile, audioread object, or file-like object\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m        path to the input file.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        Any codec supported by `soundfile` or `audioread` will work.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m        Any string file paths, or any object implementing Python's\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        file interface (e.g. `pathlib.Path`) are supported as `path`.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m        If the codec is supported by `soundfile`, then `path` can also be\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        an open file descriptor (int) or an existing `soundfile.SoundFile` object.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m        Pre-constructed audioread decoders are also supported here, see the example\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m        below.  This can be used, for example, to force a specific decoder rather\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m        than relying upon audioread to select one for you.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        .. warning:: audioread support is deprecated as of version 0.10.0.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m            audioread support be removed in version 1.0.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    sr : number > 0 [scalar]\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m        target sampling rate\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m        'None' uses the native sampling rate\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    mono : bool\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        convert signal to mono\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    offset : float\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        start reading after this time (in seconds)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    duration : float\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        only load up to this much audio (in seconds)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    dtype : numeric type\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m        data type of ``y``\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    res_type : str\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        resample type (see note)\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m        .. note::\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m            By default, this uses `soxr`'s high-quality mode ('HQ').\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m            For alternative resampling modes, see `resample`\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m        .. note::\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m           `audioread` may truncate the precision of the audio data to 16 bits.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m           See :ref:`ioformats` for alternate loading methods.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    y : np.ndarray [shape=(n,) or (..., n)]\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m        audio time series. Multi-channel is supported.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    sr : number > 0 [scalar]\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        sampling rate of ``y``\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    >>> # Load an ogg vorbis file\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    >>> filename = librosa.ex('trumpet')\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(filename)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    array([-1.407e-03, -4.461e-04, ..., -3.042e-05,  1.277e-05],\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m          dtype=float32)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    >>> sr\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    22050\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    >>> # Load a file and resample to 11 KHz\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    >>> filename = librosa.ex('trumpet')\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(filename, sr=11025)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    array([-8.746e-04, -3.363e-04, ..., -1.301e-05,  0.000e+00],\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m          dtype=float32)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    >>> sr\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;124;03m    11025\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    >>> # Load 5 seconds of a file, starting 15 seconds in\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    >>> filename = librosa.ex('brahms')\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(filename, offset=15.0, duration=5.0)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    array([0.146, 0.144, ..., 0.128, 0.015], dtype=float32)\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    >>> sr\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    22050\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    >>> # Load using an already open SoundFile object\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    >>> import soundfile\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    >>> sfo = soundfile.SoundFile(librosa.ex('brahms'))\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(sfo)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    >>> # Load using an already open audioread object\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    >>> import audioread.ffdec  # Use ffmpeg decoder\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    >>> aro = audioread.ffdec.FFmpegAudioFile(librosa.ex('brahms'))\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(aro)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mtuple\u001b[39m(audioread\u001b[38;5;241m.\u001b[39mavailable_backends())):\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Force the audioread loader if we have a reader object already\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/soundfile.py:629\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m              subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, endian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    558\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a sound file.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m    If a file is opened with `mode` ``'r'`` (the default) or\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    ``'r+'``, no sample rate, channels or file format need to be\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m    given because the information is obtained from the file. An\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m    exception is the ``'RAW'`` data format, which always requires\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m    these data points.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m    File formats consist of three case-insensitive strings:\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m    * a *major format* which is by default obtained from the\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m      extension of the file name (if known) and which can be\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m      forced with the format argument (e.g. ``format='WAVEX'``).\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    * a *subtype*, e.g. ``'PCM_24'``. Most major formats have a\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m      default subtype which is used if no subtype is specified.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    * an *endian-ness*, which doesn't have to be specified at all in\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m      most cases.\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    A `SoundFile` object is a *context manager*, which means\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    if used in a \"with\" statement, `close()` is automatically\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    called when reaching the end of the code block inside the \"with\"\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    statement.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    file : str or int or file-like object\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m        The file to open.  This can be a file name, a file\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m        descriptor or a Python file object (or a similar object with\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03m        the methods ``read()``/``readinto()``, ``write()``,\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m        ``seek()`` and ``tell()``).\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    mode : {'r', 'r+', 'w', 'w+', 'x', 'x+'}, optional\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m        Open mode.  Has to begin with one of these three characters:\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m        ``'r'`` for reading, ``'w'`` for writing (truncates *file*)\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m        or ``'x'`` for writing (raises an error if *file* already\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m        exists).  Additionally, it may contain ``'+'`` to open\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m        *file* for both reading and writing.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m        The character ``'b'`` for *binary mode* is implied because\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m        all sound files have to be opened in this mode.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m        If *file* is a file descriptor or a file-like object,\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m        ``'w'`` doesn't truncate and ``'x'`` doesn't raise an error.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    samplerate : int\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m        The sample rate of the file.  If `mode` contains ``'r'``,\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m        this is obtained from the file (except for ``'RAW'`` files).\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    channels : int\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m        The number of channels of the file.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m        If `mode` contains ``'r'``, this is obtained from the file\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m        (except for ``'RAW'`` files).\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    subtype : str, sometimes optional\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        The subtype of the sound file.  If `mode` contains ``'r'``,\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m        this is obtained from the file (except for ``'RAW'``\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m        files), if not, the default value depends on the selected\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m        `format` (see `default_subtype()`).\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m        See `available_subtypes()` for all possible subtypes for\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m        a given `format`.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    endian : {'FILE', 'LITTLE', 'BIG', 'CPU'}, sometimes optional\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m        The endian-ness of the sound file.  If `mode` contains\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m        ``'r'``, this is obtained from the file (except for\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03m        ``'RAW'`` files), if not, the default value is ``'FILE'``,\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m        which is correct in most cases.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    format : str, sometimes optional\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m        The major format of the sound file.  If `mode` contains\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m        ``'r'``, this is obtained from the file (except for\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m        ``'RAW'`` files), if not, the default value is determined\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m        from the file extension.  See `available_formats()` for\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m        all possible values.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    closefd : bool, optional\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m        Whether to close the file descriptor on `close()`. Only\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m        applicable if the *file* argument is a file descriptor.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;124;03m    >>> from soundfile import SoundFile\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m    Open an existing file for reading:\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    >>> myfile = SoundFile('existing_file.wav')\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    >>> # do something with myfile\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    >>> myfile.close()\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    Create a new sound file for reading and writing using a with\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    statement:\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    >>> with SoundFile('new_file.wav', 'x+', 44100, 2) as myfile:\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    >>>     # do something with myfile\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    >>>     # ...\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03m    >>>     assert not myfile.closed\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;124;03m    >>>     # myfile.close() is called automatically at the end\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;124;03m    >>> assert myfile.closed\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m# resolve PathLike objects (see PEP519 for details):\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# can be replaced with _os.fspath(file) for Python >= 3.6\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/soundfile.py:1183\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Close the file.  Can be called multiple times.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;66;03m# be sure to flush data to disk before closing the file\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/soundfile.py:1357\u001b[0m, in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(curr \u001b[38;5;241m+\u001b[39m frames, SEEK_SET)  \u001b[38;5;66;03m# Update read & write position\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frames\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening 'Dataset/Train/emabega/audio #4251.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m example_audio_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_DATASET_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memabega\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio #4251.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m audio_signal, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLE_RATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m audio \u001b[38;5;241m=\u001b[39m wave\u001b[38;5;241m.\u001b[39mopen(example_audio_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/librosa/core/audio.py:166\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     56\u001b[0m     path: Union[\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[Any], sf\u001b[38;5;241m.\u001b[39mSoundFile, audioread\u001b[38;5;241m.\u001b[39mAudioFile, BinaryIO\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     res_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoxr_hq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load an audio file as a floating point time series.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Audio will be automatically resampled to the given rate\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    (default ``sr=22050``).\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    To preserve the native sampling rate of the file, use ``sr=None``.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    path : string, int, pathlib.Path, soundfile.SoundFile, audioread object, or file-like object\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m        path to the input file.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m        Any codec supported by `soundfile` or `audioread` will work.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m        Any string file paths, or any object implementing Python's\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        file interface (e.g. `pathlib.Path`) are supported as `path`.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m        If the codec is supported by `soundfile`, then `path` can also be\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        an open file descriptor (int) or an existing `soundfile.SoundFile` object.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m        Pre-constructed audioread decoders are also supported here, see the example\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m        below.  This can be used, for example, to force a specific decoder rather\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m        than relying upon audioread to select one for you.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        .. warning:: audioread support is deprecated as of version 0.10.0.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m            audioread support be removed in version 1.0.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    sr : number > 0 [scalar]\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m        target sampling rate\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m        'None' uses the native sampling rate\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    mono : bool\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        convert signal to mono\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    offset : float\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        start reading after this time (in seconds)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    duration : float\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        only load up to this much audio (in seconds)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    dtype : numeric type\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m        data type of ``y``\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    res_type : str\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        resample type (see note)\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m        .. note::\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m            By default, this uses `soxr`'s high-quality mode ('HQ').\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m            For alternative resampling modes, see `resample`\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m        .. note::\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m           `audioread` may truncate the precision of the audio data to 16 bits.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m           See :ref:`ioformats` for alternate loading methods.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    y : np.ndarray [shape=(n,) or (..., n)]\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m        audio time series. Multi-channel is supported.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    sr : number > 0 [scalar]\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        sampling rate of ``y``\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    >>> # Load an ogg vorbis file\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    >>> filename = librosa.ex('trumpet')\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(filename)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    array([-1.407e-03, -4.461e-04, ..., -3.042e-05,  1.277e-05],\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m          dtype=float32)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    >>> sr\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    22050\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    >>> # Load a file and resample to 11 KHz\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    >>> filename = librosa.ex('trumpet')\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(filename, sr=11025)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    array([-8.746e-04, -3.363e-04, ..., -1.301e-05,  0.000e+00],\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m          dtype=float32)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    >>> sr\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    11025\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    >>> # Load 5 seconds of a file, starting 15 seconds in\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    >>> filename = librosa.ex('brahms')\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(filename, offset=15.0, duration=5.0)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    >>> y\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    array([0.146, 0.144, ..., 0.128, 0.015], dtype=float32)\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    >>> sr\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    22050\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    >>> # Load using an already open SoundFile object\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    >>> import soundfile\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    >>> sfo = soundfile.SoundFile(librosa.ex('brahms'))\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(sfo)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    >>> # Load using an already open audioread object\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    >>> import audioread.ffdec  # Use ffmpeg decoder\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;124;03m    >>> aro = audioread.ffdec.FFmpegAudioFile(librosa.ex('brahms'))\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    >>> y, sr = librosa.load(aro)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mtuple\u001b[39m(audioread\u001b[38;5;241m.\u001b[39mavailable_backends())):\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# Force the audioread loader if we have a reader object already\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/librosa/core/audio.py:190\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/allenv/lib/python3.10/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/Train/emabega/audio #4251.wav'"
     ]
    }
   ],
   "source": [
    "example_audio_path = os.path.join(TRAIN_DATASET_PATH, 'emabega', 'audio #4251.wav')\n",
    "audio_signal, sample_rate = librosa.load(example_audio_path, sr=SAMPLE_RATE)\n",
    "audio = wave.open(example_audio_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9f43b-560f-4ecd-8fc4-0fd733035f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_channel = audio.getnchannels()\n",
    "sample_width = audio.getsampwidth()\n",
    "frame_rate = audio.getframerate()\n",
    "number_of_frames = audio.getnframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c1779f-c100-4046-bb70-a1cb635d6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of channels:', number_of_channel)\n",
    "print('Sample width:',       sample_width)\n",
    "print('frame rate:',         frame_rate)\n",
    "print('Number of frames:',   number_of_frames)\n",
    "print('Parameters:',         audio.getparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8d1a3-acc5-436d-a053-c937cb30719c",
   "metadata": {},
   "source": [
    "### Duration of the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365737a0-ddd7-4a89-a331-7fcaaa42123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = librosa.get_duration(y=audio_signal, sr=sample_rate)\n",
    "print(f\"Duration: {duration} seconds\")\n",
    "print(f\"Sample Rate: {sample_rate} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97109ec7-8f5b-47ff-bcd7-8c3047b28a3a",
   "metadata": {},
   "source": [
    "### Visualize the audio waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9c3bc-78c2-4ed5-afae-065073e59f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(audio_signal, color='green')\n",
    "plt.title('Audio Waveform')\n",
    "plt.xlabel('ddyo')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6567df-e692-4b65-b32f-10aed24b5137",
   "metadata": {},
   "source": [
    "### Amplitude Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79384603-b574-4ce2-bbae-09ba717127f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.histplot(audio_signal, bins=50, kde=True)\n",
    "plt.title('Amplitude Distribution')\n",
    "plt.xlabel('Amplitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f95b2-f792-4438-ab45-6775b999864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stats = pd.DataFrame(audio_signal, columns=['Amplitude'])\n",
    "print(audio_stats.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2075e5-1fe0-46a9-9009-b197d367ec27",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a4e1d-b07a-460a-ada5-fb573d132ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=6):\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_AUDIO / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all sub-folders\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing the sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(f\"\\nProcessing: {semantic_label}\")\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for the current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(y=signal[start:finish],\n",
    "                                                sr=sample_rate,\n",
    "                                                n_mfcc=num_mfcc,\n",
    "                                                n_fft=n_fft,\n",
    "                                                hop_length=hop_length)\n",
    "\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with the expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(f\"{file_path}, segment:{d+1}\")\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "    # return the data dictionary\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec246ac6-5303-49a3-b0b2-329f688a29ec",
   "metadata": {},
   "source": [
    "## Save the mfcc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc490b9-438f-4b68-a0f0-34449be3b576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = save_mfcc(TRAIN_DATASET_PATH, JSON_PATH, num_segments=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9138366-b421-4f01-9eb8-e79b57ec2c1f",
   "metadata": {},
   "source": [
    "## Load json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564300f-4aca-4605-9824-76f477a39919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data successfully loaded!\")\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e969e6-cb86-4cb2-bf11-e7ddf708d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbd066-9605-4ada-8c2f-b382e1d6c55c",
   "metadata": {},
   "source": [
    "# Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0259da-7c4b-4d02-9bc4-8f743587cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8b781-61f0-4bd3-8454-5c6b1ccccf60",
   "metadata": {},
   "source": [
    "# Build a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917fba7-e4ee-48bb-8fed-af5a7546777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
    "    keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69250c-dcda-4d2b-a201-fabb53460ff6",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e5866-dcf8-45ca-8e38-6aefa0303526",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246343e-6df0-422d-877e-e7e337a5398e",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc02ec1-4362-4212-a36d-3a4b15e27573",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195796db-975f-49a5-968a-74cef5e2e0cd",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c2054-ff23-4185-a8a0-749b7f36a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad94769-d212-4e51-8974-1be31f7dc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1326491-dd91-4335-b047-d5ba9fe6a483",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327ee10-20d0-4af3-b2f9-cf4c3ae5cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')\n",
    "print(f'\\nTest loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbca69-a6be-4409-87a3-ea7846757ffe",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971ace0-6768-4dde-beff-fce327e3ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723861b-c1eb-4438-8b46-e4e5c792f96a",
   "metadata": {},
   "source": [
    "### Extract label names from the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a2a13-bb6b-4251-a0bb-b6307cea9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = data[\"mapping\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6eeea-36d3-460f-a9ef-9989f45c641c",
   "metadata": {},
   "source": [
    "### Plot confusion matrix for test set## Plot confusion matrix for test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6172221-6619-4226-877f-888ccdf80d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, label_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, xticklabels=label_names, yticklabels=label_names, annot=True, fmt='g')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c742fc6-51f3-4590-aa07-f3056e5148b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[..., tf.newaxis])\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "plot_confusion_matrix(y_test, y_pred, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe7f6c-ac51-407e-962d-12dcc5e0571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_to_display = 5\n",
    "for i in range(num_features_to_display):\n",
    "    index = np.random.randint(0, len(X_test))\n",
    "    mfcc_feature = X_test[index]\n",
    "    label = y_test[index]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(mfcc_feature.T, cmap='viridis', origin='lower', aspect='auto')\n",
    "    plt.title(f'MFCC for Feature {i + 1} (Label: {label_names[label]})')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('MFCC Coefficients')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efffddc-b46e-4cea-a0fc-2727fb19f115",
   "metadata": {},
   "source": [
    "# Save and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eeeacf-4143-440e-b732-a9d71bf5b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('audio_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c7e6a-2007-4070-aae2-15cfbf73c526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
